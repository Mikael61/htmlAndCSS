<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
                      "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="sv" xml:lang="sv">
    <head>
        <title>Recognizing Text Genres with Simple Metrics Using Discriminant Analysis &mdash; Jussi Karlgren, Douglass Cutting</title>
        <meta http-equiv="Content-Type" content="text/html;
            charset=utf-8" />
        <style type="text/css">
          body {
                width: 70% ;
                counter-reset : section ; }
          h1 { font-variant : small-caps}
          h2 { 
            counter-reset : subsection ;
               }
          h2:before
           {
          counter-increment:section;
          content:counter(section) ". ";
          font-weight:bold;
          }
          h3:before
          {
          counter-increment:subsection;
          content:counter(section) "." counter(subsection) " ";
          }
          .abstract:before {
          content:"";
          counter-reset : section ; 
          }
          .refs:before {
          content:"";
          }
          .articlename:before {
          content:open-quote
          }
          .articlename:after {
          content:close-quote
          }
         .authors { font-weight : bold}
         .opening { text-align : center}
         #p1 {float : left } 
         #p2 {float : right }
         .name:after {content: '\A';
          white-space: pre;}
         .e-mail:after {content: '\A';
          white-space: pre;}
         .date {clear : both }
         .person { width : 40% }
         .ref {margin : 1em 0em 0em 0em}
        
      </style>
    </head>
    <body>
        <div>
            <h1>Recognizing Text Genres with Simple Metrics Using Discriminant Analysis </h1>
            <div class="opening">
                <div class="person" id="p1"><span class="name">Jussi Karlgren</span> <span class="e-mail">jussi@sics.se</span> 
                    <span class="adress">Swedish Institute of
                    Computer Science Box 1263, S &mdash; 164 28 Kista, Stockholm, Sweden </span>
                </div> 
                <div class="person" id="p2"><span class="name">Douglass Cutting</span>
                    <span class="e-mail">cutting@apple.com  </span>
               
                    <span class="adress"> Apple Computer  Cupertino, CA 95014, USA </span></div>
                <p class="date">October 25, 2005 </p>
            </div>
            
            <h2 class="abstract"> Abstract </h2>
            <p> A simple method for categorizing texts into pre-determined text genre categories
                using the statistical standard technique of discriminant analysis is demonstrated
                with application to the Brown corpus. Discriminant analysis makes it possible use a
                large number of parameters that may be specific for a certain corpus or information
                stream, and combine them into a small number of functions, with the parameters
                weighted on basis of how useful they are for discriminating text genres. An
                application to information retrieval is discussed. </p>
            <h2>Text Types</h2>
            <p> There are different types of text. Texts 'about' the same thing may be in differing
                genres, of different types, and of varying quality. Texts vary along several
                parameters, all relevant for the general information retrieval problem of matching
                reader needs and texts. Given this variation, in a text retrieval context the
                problems are (i) identifying genres, and (ii) choosing criteria to cluster texts of
                the same genre, with predictable precision and recall. This should not be confused
                with the issue of identifying topics, and choosing criteria that discriminate one
                topic from another. Although not orthogonal to genre-dependent variation, the
                variation that relates directly to content and topic is along other dimensions.
                Naturally, there is co-variance. Texts about certain topics may only occur in
                certain genres, and texts in certain genres may only treat certain topics; most
                topics do, however, occur in several genres, which is what interests us here.
                </p><p> Douglas Biber has studied text variation along several parameters, and found
                that texts can be considered to vary along five dimensions. In his study, he
                clusters features according to covariance, to find underlying dimensions (1989). We
                wish to find a method for identifying easily computable parameters that rapidly
                classify previously unseen texts in general classes and along a small set &mdash; smaller
                than Biber's five &mdash; of dimensions, such that they can be explained in intuitively
                simple terms to the user of an information retrieval application. Our aim is to take
                a set of texts that <em>has</em> been selected by some sort of crude semantic analysis such
                as is typically performed by an information retrieval system and partition it
                <em>further</em> by genre or text type, and to display this variation as simply as possible
                in one or two dimensions. </p>
            
            <h2> Method </h2>
            <p>We start by using features similar to those first investigated by Biber, but we
                concentrate on those that are easy to compute assuming we have a part of speech
                tagger (Cutting et al, 1992; Church, 1988), such as such as third person pronoun
                occurrence rate as opposed to <span class="term">general hedges</span> (Biber, 1989). More and more of
                Biber's features will be available with the advent of more proficient analysis
                programs, for instance if complete surface syntactic parsing were performed before
                categorization (Voutilainen &amp; Tapanainen, 1993). </p><p>We then use discriminant
                analysis, a technique from descriptive statistics. Discriminant analysis takes a set
                of precategorized individuals and data on their variation on a number of parameters,
                and works out a set <em>discriminant functions</em> which distinguishes between the groups.
                These functions can then be used to predict the category memberships of new
                individuals based on their parameter scores (Tatsuoka, 1971; Mustonen, 1965).
                </p><h2>Evaluation </h2><p>For data we used the Brown corpus of English text samples
                of uniform length, categorized in several categories as seen in table 1. We ran
                discriminant analysis on the texts in the corpus using several different features as
                seen in table 2. We used the SPSS system for statistical data analysis, which has as
                one of its features a complete discriminant analysis (SPSS, 1990). The discriminant
                function extracted from the data by the analysis is a linear combination of the
                parameters. To categorize a set into N categories N &mdash; 1 functions need to be
                determined. </p>
            <div class="table">Table 1: Categories in the Brown Corpus </div>
            <div  class="table"> Table 2: Parameters for Discriminant Analysis </div>
            <div  class="table"> Table 3: Categorization in Two Categories </div>
            <div class="figure"> <img src="https://raw.githubusercontent.com/Mikael61/htmlAndCSS/main/figure2.png" alt="Distribution, 2 categories"/> Figure 1: Distribution, 2 Categories </div>
            <p> However, if we are content with being able to plot all categories on a
                two-dimensional plane, which probably is what we want to do, for ease of exposition,
                we only use the two first and most significant functions. </p>
            <h3> 2 categories </h3>
            <p> In the case of two categories, only one function is necessary for determining the
                category of an item. The function classified 478 cases correctly and misclassified
                22, out of the 500 cases, as shown in table 3 and figure 1. </p>
            <h3> 4 categories </h3>
            <p> Using the three functions extracted, 366 cases were correctly classified, and 134
                cases were misclassified, out of the 500 cases, as can be seen in table 4 and figure
                2. 'Miscellaneous', the most problematic category, is a loose grouping of different
                informative texts. The single most problematic subsubset of texts is a subset of
                eighteen non-fiction texts labeled 'learned/humanities'. Sixteen of them were
                misclassified, thirteen as 'miscellaneous'. </p>
            <h3>15 (or 10) categories </h3>
            
            <p>Using the fourteen functions extracted, 258 cases were
                correctly classified and 242 cases misclassified out of the 500 cases, as shown in
                table 5. Trying to distinguish between the different types of fiction is expensive
                in terms of errors. If the fiction subcategories were collapsed there only would be
                ten categories, and the error rate for the categorization would improve as shown in
                the 'revised total' record of the table. The 'learned/humanities' subcategory is, as
                before, problematic: only two of the eighteen items were correctly classified. The
                others were most often misclassified as 'Religion' or 'Belles Lettres'.
                </p>
            
            <h2>Validation of the Technique </h2>
            <p>It is important to note that this
                experiment does not claim to show <em>how</em> genres in fact differ. What we show is that
                this sort of technique <em>can be</em> used to determine which parameters to use, given a set
                of them. We did not use a test set disjoint from the training set, and we do not
                claim that the functions we had the method extract from the data are useful in
                themselves. We discuss how well this method categorizes a set text, given a set of
                categories, and given a set of parameters. </p>
            <p>The error rates climb steeply with the number of categories tested for in the corpus
                we used. This may have to do with how the categories are chosen and defined. For
                instance, distinguishing between di erent types of fiction by formal or stylistic
                criteria of this kind may just be something we should not attempt: the fiction types
                are naturally defined in terms of their content, after all. </p>
            
            <p>The statistical
                technique of <em>factor analysis</em> can be used to discover categories, like Biber has
                done. The problem with using automatically derived categories is that even if they
                are in a sense real, meaning that they are supported by data, they may be diØcult to
                explain for the unenthusiastic layman if the aim is to use the technique in
                retrieval tools. </p>
            <p>Other criteria that should be studied are second and higher
                order statistics on the respective parameters. Certain parameters probably <em>vary more</em>
                in certain text types than others, and they may have a <em>skewed distribution</em> as well.
                This is not diffcult to determine, although the standard methods do not support
                automatic determination of standard deviation or skewness as discrimination
                criteria. Together with the investigation of several hitherto untried parameters,
                this is a next step. </p>
            
            <h2>Readability Indexing </h2>
            
            <p>Not unrelated to the study
                of genre is the study of <em>readability</em> which aims to categorize texts according to
                their suitability for assumed sets of assumed readers. There is a wealth of formulæ
                to compute readability. Most commonly they combine easily computed text measures,
                typically average or sampled average sentence length combined with similarly
                computed word length, or incidence of words not on a specified <span class="term">easy word list</span>
                (Chall, 1948; Klare, 1963). In spite of Chall's warnings about injudicious
                application to writing tasks, readability measurement has naively come to be used as
                a prescriptive metric of good writing as a tool for writers, and has thus come into
                some disrepute among text researchers. Our small study confirms the basic findings
                of the early readability studies: the most important factors of the ones we tested
                are word length, sentence length, and different derivatives of these two parameters.
                As long as readability indexing schemes are used in descriptive applications they
                work well to discriminate between text types. </p>
            
            <h2>Application </h2>
            
            <p>The
                technique shows practical promise. The territorial maps shown in figures 1, 2, and 3
                are intuitively useful tools for displaying what type a particular text is, compared
                with other existing texts. The technique demonstrated above has an obvious
                application in information retrieval, for picking out interesting texts, if content
                based methods select a too large set for easy manipulation and browsing (Cutting et
                al, 1992). </p> 
            
            <div  class="table">Table 4: Categorization in Four Categories </div>
            
            <div class="figure">Figure 2: Distribution, 4
            Categories </div>
            
            <div  class="table">Table 5: Categorization in 15 Categories </div>
            
            <p>In any specific application area
                it will be unlikely that the text database to be accessed will be completely free
                form. The texts under consideration will probably be specific in some way. General
                text types may be useful, but quite probably there will be a domain-or
                field-specific text typology. In an envisioned application, a user will employ a
                cascade of filters starting with filtering by topic, and continuing with filters by
                genre or text type, and ending by filters for text quality, or other tentative
                finer-grained qualifications. </p><h2>The IntFilter Project </h2>
            <p>The IntFilter Project at the departments of Computer and Systems Sciences,
                Computational Linguistics, and Psychology at Stockholm University is at present
                studying texts on the USENET News conferencing system. The project at present
                studies texts which appear on several di erent types of USENET News conferences, and
                investigates how well the classification criteria and categories that experienced
                USENET News users report using (IntFilter, 1993) can be used by a newsreader system.
                To do this the project applies the method described here. The project uses
                categories such as 'query', 'comment', 'announcement', 'FAQ', and so forth,
                categorizing them using parameters such as different types of length measures, form
                word content, quote level, percentage quoted text and other USENET News specific
                parameters. </p>
            
            <h2>Acknowledgements </h2><p>Thanks to Hans Karlgren, Gunnel
                Källgren, Geoff Nunberg, Jan Pedersen, and the Coling referees, who all have
                contributed with suggestions and methodological discussions. </p> 
            
     <div class="figure">       Figure 3:
            Distribution, 15 Categories &mdash; * Indicates a group centroid. </div>
            
            <h2 class="refs">References</h2>
            <div class="ref"><span class="authors">Douglas Biber</span> 1989. <span class="articlename">A typology of English texts</span>, Linguistics,
                27:3-43. </div>
            <div class="ref"><span class="authors">Jeanne S. Chall</span> 1948. Readability, Ohio State Univ. </div>
            <div class="ref"><span class="authors">Kenneth Church</span> 1988. <span class="articlename" >A Stochastic Parts of Speech and Noun Phrase
                Parser for Unrestricted Text</span>, Procs. 2nd ANLP, Austin. </div>
            <div class="ref"><span class="authors">Douglass Cutting, Julian Kupiec, Jan Pedersen, and Penelope Sibun</span> 1992.
                <span class="articlename">A Practical Part-of-Speech Tagger</span>, Procs. 3rd ANLP, Trento. </div>
            <div class="ref"><span class="authors">Douglass Cutting, D. Karger, Jan Pedersen, and John Tukey</span> 1992.
                <span class="articlename">Scatter/Gather: A Cluster-based Approach to Browsing Large Document Collections</span>
                Procs. SIGIR92. </div>
            <div class="ref"><span class="authors">IntFilter</span> 1993. Working Papers of the IntFilter Project, available by
                gopher from dsv.su.se:/pub/IntFilter. </div>
            <div class="ref"><span class="authors">George R. Klare</span> 1963. The Measurement of Readability, Iowa Univ press. </div>
            <div class="ref"><span class="authors">W. N. Francis and F. Kučera 1982</span>. Frequency Analysis of English Usage,
                Houghton Mifflin. </div>
            <div class="ref"><span class="authors">Seppo Mustonen</span> 1965. <span class="articlename">Multiple Discriminant Analysis in Linguistic
                Problems</span>, Statistical Methods in Linguistics, 4:37-44. </div>
            <div class="ref"><span class="authors">M. M. Tatsuoka</span> 1971. Multivariate Analysis, New York:John Wiley &amp;
                Sons. </div>
            <div class="ref"><span class="authors">Atro Voutilainen and Pasi Tapanainen</span> 1993. <span class="articlename">Ambiguity resolution in a
                reductionistic parser</span>, Procs. 6th European ACL, Utrecht. </div>
            <div class="ref"><span class="authors">SPSS</span> 1990. The SPSS Reference Guide, Chicago: SPSS Inc. </div></div>
    </body>
</html>
